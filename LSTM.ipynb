{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all songs\n",
    "songs = []\n",
    "for f in os.listdir(\"data/preprocessed\"):\n",
    "    songs.append(np.genfromtxt((\"data/preprocessed/%s\" % f), dtype=int, delimiter=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  29293\n"
     ]
    }
   ],
   "source": [
    "# Split data up into \"patterns\"\n",
    "# normalize ints by dividing by 128\n",
    "pattern_length = 100\n",
    "data_X = []\n",
    "data_y = []\n",
    "for f in songs[:10]:\n",
    "    for i in range(0, len(f) - pattern_length, 1):\n",
    "        data_X.append(f[i:i+pattern_length])\n",
    "        data_y.append(f[i+pattern_length])\n",
    "n_patterns = len(data_X)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unused notes\n",
    "freq = np.bincount(np.array(data_X).flatten())\n",
    "\n",
    "# Get indices of nonzero frequencies\n",
    "non_zero_freq = np.nonzero(freq)[0]\n",
    "\n",
    "# Remember highest and lowest used notes\n",
    "lowest = non_zero_freq[0]\n",
    "highest = non_zero_freq[len(non_zero_freq) - 1]\n",
    "n_notes = highest - lowest + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X\n",
    "X = np.reshape(data_X, (n_patterns, pattern_length, 1))\n",
    "\n",
    "# Normalize\n",
    "X = (X - lowest) / n_notes\n",
    "\n",
    "# One hot encode\n",
    "y = np_utils.to_categorical(data_y - lowest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=((pattern_length, 1)), return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(256, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_notes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints\n",
    "checkpoint = ModelCheckpoint(\"checkpoint-{epoch:02d}.hdf5\", monitor='loss', verbose=1, save_best_only=True, mode='min', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "29293/29293 [==============================] - 2845s 97ms/step - loss: 2.9267 - categorical_accuracy: 0.3790\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.92672, saving model to checkpoint-01.hdf5\n",
      "Epoch 2/20\n",
      "29293/29293 [==============================] - 2806s 96ms/step - loss: 2.8387 - categorical_accuracy: 0.3805\n",
      "\n",
      "Epoch 00002: loss improved from 2.92672 to 2.83868, saving model to checkpoint-02.hdf5\n",
      "Epoch 3/20\n",
      "29293/29293 [==============================] - 2716s 93ms/step - loss: 2.7346 - categorical_accuracy: 0.3805\n",
      "\n",
      "Epoch 00003: loss improved from 2.83868 to 2.73456, saving model to checkpoint-03.hdf5\n",
      "Epoch 4/20\n",
      "29293/29293 [==============================] - 2724s 93ms/step - loss: 2.5094 - categorical_accuracy: 0.3854\n",
      "\n",
      "Epoch 00004: loss improved from 2.73456 to 2.50943, saving model to checkpoint-04.hdf5\n",
      "Epoch 5/20\n",
      "29293/29293 [==============================] - 2725s 93ms/step - loss: 2.3118 - categorical_accuracy: 0.4005\n",
      "\n",
      "Epoch 00005: loss improved from 2.50943 to 2.31181, saving model to checkpoint-05.hdf5\n",
      "Epoch 6/20\n",
      "29293/29293 [==============================] - 2738s 93ms/step - loss: 2.1941 - categorical_accuracy: 0.4155\n",
      "\n",
      "Epoch 00006: loss improved from 2.31181 to 2.19412, saving model to checkpoint-06.hdf5\n",
      "Epoch 7/20\n",
      "29293/29293 [==============================] - 2723s 93ms/step - loss: 2.0843 - categorical_accuracy: 0.4306\n",
      "\n",
      "Epoch 00007: loss improved from 2.19412 to 2.08430, saving model to checkpoint-07.hdf5\n",
      "Epoch 8/20\n",
      "29293/29293 [==============================] - 2725s 93ms/step - loss: 2.0002 - categorical_accuracy: 0.4446\n",
      "\n",
      "Epoch 00008: loss improved from 2.08430 to 2.00017, saving model to checkpoint-08.hdf5\n",
      "Epoch 9/20\n",
      "29293/29293 [==============================] - 2726s 93ms/step - loss: 1.9117 - categorical_accuracy: 0.4622\n",
      "\n",
      "Epoch 00009: loss improved from 2.00017 to 1.91167, saving model to checkpoint-09.hdf5\n",
      "Epoch 10/20\n",
      "29293/29293 [==============================] - 2722s 93ms/step - loss: 1.8310 - categorical_accuracy: 0.4755\n",
      "\n",
      "Epoch 00010: loss improved from 1.91167 to 1.83097, saving model to checkpoint-10.hdf5\n",
      "Epoch 11/20\n",
      "29293/29293 [==============================] - 2722s 93ms/step - loss: 1.7480 - categorical_accuracy: 0.4948\n",
      "\n",
      "Epoch 00011: loss improved from 1.83097 to 1.74798, saving model to checkpoint-11.hdf5\n",
      "Epoch 12/20\n",
      "29293/29293 [==============================] - 2720s 93ms/step - loss: 1.6956 - categorical_accuracy: 0.5052\n",
      "\n",
      "Epoch 00012: loss improved from 1.74798 to 1.69562, saving model to checkpoint-12.hdf5\n",
      "Epoch 13/20\n",
      "29293/29293 [==============================] - 2716s 93ms/step - loss: 1.6032 - categorical_accuracy: 0.5233\n",
      "\n",
      "Epoch 00013: loss improved from 1.69562 to 1.60318, saving model to checkpoint-13.hdf5\n",
      "Epoch 14/20\n",
      "23360/29293 [======================>.......] - ETA: 9:09 - loss: 1.5448 - categorical_accuracy: 0.5369"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-886f3c2ae6a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=20, batch_size=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \n",
    "filename = \"checkpoint-13.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = np.random.randint(0, len(data_X) - 1)\n",
    "pattern=X[start]\n",
    "song = []\n",
    "#Generate\n",
    "for i in range(200):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    prediction = model.predict(x, verbose=0).flatten()\n",
    "    index=np.argmax(prediction)\n",
    "    pattern = np.append(pattern, (index/float(n_notes)))\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "    song = np.append(song, (index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128.  86.  83.  82. 128.  82.  91.  83.  86.  91. 128. 128.  91.  86.\n",
      "  83.  83.  86.  91. 128.  86.  83.  82. 128.  82.  91.  83.  86.  91.\n",
      " 128. 128.  91.  86.  83.  83.  86.  91. 128.  86.  83.  82. 128.  82.\n",
      "  91.  83.  86.  91. 128. 128.  91.  86.  83.  83.  86.  91. 128.  86.\n",
      "  83.  82. 128.  82.  91.  83.  86.  91. 128. 128.  91.  86.  83.  83.\n",
      "  86.  91. 128.  86.  83.  82. 128.  82.  91.  83.  86.  91. 128. 128.\n",
      "  91.  86.  83.  83.  86.  91. 128.  86.  83.  82. 128.  82.  91.  83.\n",
      "  86.  91.]\n"
     ]
    }
   ],
   "source": [
    "print((pattern*n_notes) + lowest)\n",
    "np.savetxt(\"song.csv\", (song + lowest), fmt='%s', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
