{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all songs\n",
    "songs = []\n",
    "for f in os.listdir(\"data/preprocessed\"):\n",
    "    songs.append(np.genfromtxt((\"data/preprocessed/%s\" % f), dtype=int, delimiter=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  362770\n"
     ]
    }
   ],
   "source": [
    "# Split data up into \"patterns\"\n",
    "# normalize ints by dividing by 128\n",
    "pattern_length = 500\n",
    "data_X = []\n",
    "data_y = []\n",
    "for f in songs:\n",
    "    for i in range(0, len(f) - pattern_length, 1):\n",
    "        data_X.append(f[i:i+pattern_length])\n",
    "        data_y.append(f[i+pattern_length])\n",
    "n_patterns = len(data_X)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unused notes\n",
    "freq = np.bincount(np.array(data_X).flatten())\n",
    "\n",
    "# Get indices of nonzero frequencies\n",
    "non_zero_freq = np.nonzero(freq)[0]\n",
    "\n",
    "# Remember highest and lowest used notes\n",
    "lowest = non_zero_freq[0]\n",
    "highest = non_zero_freq[len(non_zero_freq) - 1]\n",
    "n_notes = highest - lowest + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape X\n",
    "X = np.reshape(data_X, (n_patterns, pattern_length, 1))\n",
    "\n",
    "# Normalize\n",
    "X = (X - lowest) / n_notes\n",
    "\n",
    "# One hot encode\n",
    "y = np_utils.to_categorical(data_y - lowest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=((pattern_length, 1)), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(n_notes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoints\n",
    "checkpoint = ModelCheckpoint(\"checkpoint-{epoch:02d}.hdf5\", monitor='loss', verbose=1, save_best_only=True, mode='min', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "   256/362770 [..............................] - ETA: 4:11:33 - loss: 4.6482 - categorical_accuracy: 0.0078"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=5, batch_size=256, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \n",
    "filename = \"name\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = np.random.randint(0, len(dataX) - 1)\n",
    "pattern=dataX[start]\n",
    "#Generate\n",
    "for i in range(100):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(129)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index=np.argmax(prediction)\n",
    "    pattern = np.append(pattern, (index))\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\n",
      " 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\n",
      " 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\n",
      " 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\n",
      " 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128 128\n",
      " 128 128 128 128 128 128 128 128 128 128]\n"
     ]
    }
   ],
   "source": [
    "print(pattern + lowest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
